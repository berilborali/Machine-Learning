{\rtf1\ansi\ansicpg1252\cocoartf2636
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 ArialMT;\f1\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs29\fsmilli14667 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 First, we will analyze our results then we will compare them with the ones obtained in the suggested research paper for the assignment \'93The Five Factor Model of personality and evaluation of drug consumption risk\'93.
\f1\fs24 \
\

\f0\fs29\fsmilli14667 As shown in the ROC curves, Random Forest Classifier has the highest AUC (area under the curve) score which means that it is the model with the highest performance overall among all the 4 types of learning models. Decision Tree has the lowest AUC score in almost all the drug classes among the four types of learnings. Besides the AUC scores, another way to visually understand the ROC curves is that the closer a curve gets to the diagonal line, the lower the performance of the model would be. We see that Random Forest classifier is the curve that is the farthest to the diagonal line, while Decision Tree and KNN have the closest curves to the diagonal overall, especially in the case of the Alcohol. Since the data was unbalanced, we can see how this reflects on the predictions in the Confusion Matrices especially for Alcohol. The confusion matrices for all the 4 models of Alcohol shows that it was\'a0 supports what we\'a0
\f1\fs24 \

\f0\fs29\fsmilli14667 Among all the drugs,\'a0
\f1\fs24 \
\

\f0\fs29\fsmilli14667 Comparing my results with the ones in the suggested research paper for this assignment, my first remark was, on Table 18 on page 34, that almost all of their best results were produced by Decision Tree Classifier and their second best results by k-Nearest Neighbor Classifier, unlike our results. Additionally, they kept only 2 to 6 input features which had been selected using a \'93method which maximises value of the minimum of sensitivity and specificity\'94 for each of the drugs. Hence, unlike them, the fact that I kept all the 12 input features while training my models may have an impact on this difference in our results since the unnecessary features could have a negative impact on the learning process.\'a0
\f1\fs24 \
\
}